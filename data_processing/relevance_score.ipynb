{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytrends.request import TrendReq \n",
    "from datetime import date, timedelta\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plot\n",
    "import numpy as np\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script is for counting \"relevance scores\". The current score calculation is rather vague. Scores are compareable only within one geo location.\n",
    "\n",
    "TODO: \n",
    "- Check the normalization words (especially the global's)\n",
    "- Check the month span to be used \n",
    "- Build a pipeline that calculates the score for all the blogs (using preferably some extracted keywords etc.) \n",
    "- For final version, remove all the unnecessary print commands\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function, that counts the the \"relevance score\" for one 4-word-batch\n",
    "# Input_kw,         a list containing max 4 keywords\n",
    "# search year,      int\n",
    "# search month,     int\n",
    "# comp_word,        Comparison word(str) that will be used to get google to somewhat normalize to same standards \n",
    "# geo,              two letter abbrevation (str) for geo location\n",
    "def count_relevance_score_single(input_kw, search_year, search_month, comp_word, geo, return_score = True):\n",
    "    # \"Constants\" that could be attuned\n",
    "    months_before = 2       # months to take account\n",
    "    months_after  = 0\n",
    "\n",
    "    comp_time = \"2010-01-01 \" + date.today().isoformat() \n",
    "    kw_list = [comp_word] + input_kw\n",
    "\n",
    "    # Quering the data from google\n",
    "    # If Google returns code 429, it means that the code is ok, but google didn't want to co-operate for some reason. Solved by retrying. If that doesn't work wait 60s and try again.\n",
    "    # Code 400 means probably, that something was wrong with the input parameters\n",
    "    pytrends = TrendReq(hl='en-US', tz=-120, timeout=(10,25), retries = 4, backoff_factor=0.1)\n",
    "    pytrends.build_payload(kw_list, timeframe=comp_time, geo = geo)\n",
    "    loc_df = pytrends.interest_over_time()\n",
    "\n",
    "    # Finding correct indices\n",
    "    index = np.where((loc_df.index.year ==  search_year) & (loc_df.index.month == search_month))\n",
    "\n",
    "    if len(index) < 1:\n",
    "        print(\"ERROR: comparison data not found for specified year and month\")\n",
    "\n",
    "    if len(loc_df[loc_df[comp_word] > 95]) < 1:\n",
    "        print(\"WARNING: Score is too small and won't give good explanation!\")\n",
    "        print(\"For words:\" + str(kw_list) + \" the found maximum is \" + str(loc_df[comp_word].max()) + \" , when it should be 100.\")\n",
    "\n",
    "    index = int(index[0])\n",
    "\n",
    "    if return_score:\n",
    "        # count sum and normalize it by dividing it with the number of months and number of keywords\n",
    "        return loc_df.iloc[index-months_before : index + months_after + 1, 1:-1].sum(axis=0).sum()/((months_before+months_after+1)*(len(input_kw)))\n",
    "\n",
    "    return loc_df.iloc[index-months_before : index + months_after + 1, 1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function, that splits the keyword list into max 4 word chuncks\n",
    "def count_relevance_score_multi(input_kw, search_year, search_month, comp_word, geo, return_score = True):\n",
    "    iterations_num = ceil(len(input_kw)/4.0)\n",
    "\n",
    "    if return_score:\n",
    "        score = 0\n",
    "        for index in range(iterations_num):\n",
    "            score += count_relevance_score_single(input_kw[index*4 : min((index+1)*4, len(input_kw))], search_year, search_month, comp_word, geo)\n",
    "        return score/iterations_num\n",
    "\n",
    "    return_df = pd.DataFrame([])\n",
    "\n",
    "    for index in range(iterations_num):\n",
    "        return_df = pd.concat([return_df, count_relevance_score_single(input_kw[index*4 : min((index+1)*4, len(input_kw))], search_year, search_month, comp_word, geo)], axis=1)\n",
    "\n",
    "    return return_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function that counts the \"relevance score\" based on google trends data\n",
    "inputs:     Input_kw:                          - List of keywords\n",
    "            search_year                        - Int\n",
    "            search_month                       - Int\n",
    "            Geos options: all                  - Will use all countries Futurice has currently office\n",
    "                        {FI, SE, NO, DE, GB}   - Will use only the country the abbrevation is refering to\n",
    "                        \"\"                     - Will use the default, which is whole world. WARNING: Might not give any meaningfull results \n",
    "            return_score = True                - if True, returns a float, else returns a dataframe with specified months and keywords. Prefer True, as False is mainly for debuging and more error prone\"\"\"           \n",
    "\n",
    "def count_relevance_score(input_kw, search_year, search_month, geos, return_score = True):\n",
    "    geos_dict = {\"FI\" : \"Finland\", \"SE\" : \"Sweden\", \"NO\": \"Norway\", \"DE\": \"Germany\", \"GB\" : \"English\"} # Location abbreavations and their corresponding default \"normalization\" words\n",
    "\n",
    "    if geos == \"\":\n",
    "        return count_relevance_score_multi(input_kw, search_year, search_month, \"Finland\", \"\", return_score=return_score)\n",
    "\n",
    "    if geos == \"all\":\n",
    "        score = 0\n",
    "        for item in geos_dict:\n",
    "            score += count_relevance_score_multi(input_kw, search_year, search_month, geos_dict[item], item)\n",
    "        return score/len(geos_dict)\n",
    "            \n",
    "\n",
    "    if geos not in geos_dict:\n",
    "        print(\"Given country abbrevation was incorrect! \\nReturning no results.\")\n",
    "        return\n",
    "\n",
    "    return count_relevance_score_multi(input_kw, search_year, search_month, geos_dict[geos], geos, return_score=return_score)\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some grude tests.\n",
    "\n",
    "Remove rest of this notebook to transform this to regular python script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.033333333333333"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_relevance_score([\"Passion\", \"AI\" ], 2022, 6, \"all\", return_score = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FI: 3.3333333333333335\n",
      "SE: 3.5\n",
      "NO: 2.3333333333333335\n",
      "DE: 6.833333333333333\n",
      "GB: 4.166666666666667\n"
     ]
    }
   ],
   "source": [
    "for item in [\"FI\", \"SE\", \"NO\", \"DE\", \"GB\"]:\n",
    "    print(str(item) + \": \" + str(count_relevance_score([\"Passion\", \"AI\" ], 2022, 6, item, return_score = True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.911111111111111"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_relevance_score([\"Passion\", \"AI\", \"Gaming\", \"Tech\", \"Management\", \"Python\", \"Ruby\", \"C#\", \"Nobody\"], 2022, 6, \"all\", return_score = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Score is too small and won't give good explanation!\n",
      "For words:['Finland', 'Passion', 'AI', 'Gaming', 'Tech'] the found maximum is 18 , when it should be 100.\n",
      "WARNING: Score is too small and won't give good explanation!\n",
      "For words:['Finland', 'Management', 'Python', 'Ruby', 'C#'] the found maximum is 12 , when it should be 100.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "47.02777777777777"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_relevance_score([\"Passion\", \"AI\", \"Gaming\", \"Tech\", \"Management\", \"Python\", \"Ruby\", \"C#\", \"Nobody\"], 2022, 6, \"\", return_score = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('DS project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ade64e42b5cacb24cdbfb2325a9485ebd4e72a0fd6d9fec45d81febe1d9f8011"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
